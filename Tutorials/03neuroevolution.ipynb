{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## epann\n",
    "\n",
    "##### Evolutionary Plastic Artificial Neural Networks\n",
    "\n",
    "\n",
    "Back to [Part 2: Simulating Agents that Learn](02agentsenvs.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuroevolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "If we would like to evolve a population of our example agents on the task described in **Part 2**, it is important that we have a stable representation of an artificial neural network. With that representation, it will be possible to have two agent's reproduce, as well as mutate a single genome with each generation. \n",
    "\n",
    "Within the field of neuroevolution, there are generally two different types of neural network representations we can choose as our agent genome: *direct* and *indirect encodings*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Direct Encodings\n",
    "\n",
    "Since we need to find a representation for an agent in our population described in **Part 2**, let's start with the simplest agent of that kind: a fully-connected neural network with 3 output nodes, 6 input nodes, and no hidden nodes. (**Figure 3.1**)\n",
    "\n",
    "##### Figure 3.1 - Simplest Agent Neural Network\n",
    "\n",
    "![Figure 3.1](figures/simplestnet.png)\n",
    "\n",
    "A directly encoded genome contains a one-to-one relationship between the parameters that describe the neural network and the number of genes in the associated agent genome. \n",
    "\n",
    "For example, an agent with the network shown in **Figure 3.1** has 18 unique weights, and therefore a direct encoding of that agent will require at least 18 values. It may additionally require information about the number of inputs, outputs, the activation functions used in those outputs, as well parameters that influence its learning within the environment. \n",
    "\n",
    "For the purpose of our very simple task, 18 weight values is not very much. It would not be difficult to apply standard gradient-based learning to find the appropriate parameters for this model. If we did want to represent the network with a genome, 18 genes for each of the weights is relatively small, and we don't run into many problems performing reproduction on mutation on it. \n",
    "\n",
    "However, a direct encoding presents difficulty as a general purpose representation for neural networks. Direct encodings will also require as many genes as there are parameters for more complex models, such as modern benchmark convolutional neural networks, which may contain over a million parameters. Using a genetic algorithm in a space that large will be difficult, and it is likely that candidate solutions will bounce around the space without converging. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indirect Encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move on to [Part 4: Compositional Pattern Producing Networks](04cppns.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
